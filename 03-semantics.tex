% \newcommand{\NST}{\1\xrightarrow[\mathit{nst}]\1}
% \newcommand{\OUT}{\1\xrightarrow[\mathit{out}]\1}
% \newcommand{\LL}{\langle}
% \newcommand{\RR}{\rangle}
% \newcommand{\DS}{\displaystyle}

% \newcommand{\1}{\;}
% \newcommand{\2}{\;\;}
% \newcommand{\3}{\;\;\;}
% \newcommand{\5}{\;\;\;\;\;}

\def\JOT{1.5\jot}

\section{Formal Semantics}
\label{sec.sem}

In this section, we introduce a reduced syntax for \CEU and propose an
operational semantics to formally describe the behavior of its programs.
We describe a small synchronous kernel highlighting the peculiarities of \CEU,
in particular, the stack-based execution for internal events.
%
For the sake of simplicity, we focus on the control aspects of the language,
leaving out side-effects and system calls (which behave like in conventional
imperative languages).

\subsection{Abstract Syntax}
\label{sec.sem.syntax}

%-
% \begin{lstlisting}[
%   %numbers=left,
%   basicstyle=\ttfamily\footnotesize,
%   float=h,
%   caption={Reduced syntax of \CEU.},
%   label={lst.formal.syntax},
%   mathescape=true
% ]
%                                    // primary expressions
%   p ::= mem(id)                    (any memory access to `id')
%       $|$ awaitExt(id)               (await external event `id')
%       $|$ awaitInt(id)               (await internal event `id')
%       $|$ emitInt(id)                (emit internal event `id')
%       $|$ break                      (loop escape)
%                                    // compound expressions
%       $|$ if mem(id) then p else p   (conditional)
%       $|$ p ; p                      (sequence)
%       $|$ loop p                     (repetition)
%       $|$ every id p                 (event iteration)
%       $|$ p and p                    (par/and)
%       $|$ p or p                     (par/or)
%       $|$ fin p                      (finalization)
%                                    // derived by semantic rules
%       $|$ p @loop p                  (unwinded loop)
%       $|$ p @and q                   (unwinded par/and)
%       $|$ p @or q                    (unwinded par/or)
%       $|$ @canrun(n)                 (can run on stack level `n')
%       $|$ @nop                       (terminated expression)
% \end{lstlisting}
%-

The grammar below defines the syntax of a subset of \CEU that is
sufficient to describe all semantic peculiarities of the language.
\bgroup
\def\lbl#1{\quad\text{\emph{#1}}}%
\newdimen\X
\X=-1\jot
\begin{alignat*}{2}
  P\Coloneqq
      &\enspace\ceu{\Mem(\Id)}
      &&\lbl{any memory access to~``$\ceu\Id$''}\\[\X]
      %%
  \mid&\enspace\ceu{\AwaitExt(\Id)}
      &&\lbl{await external event~``$\ceu\Id$''}\\[\X]
      %%
  \mid&\enspace\ceu{\AwaitInt(\Id)}
      &&\lbl{await internal event~``$\ceu\Id$''}\\[\X]
      %%
  \mid&\enspace\ceu{\EmitInt(\Id)}
      &&\lbl{emit internal event~``$\ceu\Id$''}\\[\X]
      %%
  \mid&\enspace\ceu{\Break}
      &&\lbl{loop escape}\\[\X]
      %%
  \mid&\enspace\ceu{\IfElse{\Mem(\Id)}{P_1}{P_2}}
      &&\lbl{conditional}\\[\X]
      %%
  \mid&\enspace\ceu{P_1\,;\,P_2}
      &&\lbl{sequence}\\[\X]
      %%
  \mid&\enspace\ceu{\Loop P_1}
      &&\lbl{repetition}\\[\X]
      %%
  \mid&\enspace\ceu{\Every{\Id}\ P_1}
      &&\lbl{event iteration}\\[\X]
      %%
  \mid&\enspace\ceu{P_1\And P_2}
      &&\lbl{par/and}\\[\X]
      %%
  \mid&\enspace\ceu{P_2\Or P_2}
      &&\lbl{par/or}\\[\X]
      %%
  \mid&\enspace\ceu{\Fin P}
      &&\lbl{finalization}\\[\X]
      %%
  \mid&\enspace\ceu{P_1\AtLoop P_2}
      &&\lbl{unwinded loop}\\[\X]
      %%
  \mid&\enspace\ceu{P_1\AtAnd\ P_2}
      &&\lbl{unwinded par/and}\\[\X]
      %%
  \mid&\enspace\ceu{P_1\AtOr\ P_2}
      &&\lbl{unwinded par/or}\\[\X]
      %%
  \mid&\enspace\ceu{\CanRun(n)}
      &&\lbl{can run on stack level~$n$}\\[\X]
      %%
  \mid&\enspace\ceu{\Nop}
      &&\lbl{terminated program}
\end{alignat*}
\egroup

The~$\ceu{\Mem(id)}$ primitive represents all accesses, assignments, and system
calls that affect a memory location identified by~$id$.
%
According to the synchronous hypothesis of \CEU, $\ceu{\Mem}$ expressions are
considered to be atomic and instantaneous.
%
As the challenging parts of \CEU reside on its control structures, we are not
concerned here with a precise semantics for side effects, but only with their
occurrences in programs.
%
%The special notation $nop$ is used to represent an innocuous $mem$ expression
%(it can be thought as a synonym for $mem(\epsilon)$, where $\epsilon$ is an
%unused identifier).

We assume that $\ceu{\Mem}$, $\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$
and~$\ceu{\EmitInt}$ expressions do not share identifiers:
any identifier is either a variable, an external event, or an internal event.

Most expressions in the abstract language are mapped to their counterparts in
the concrete language.
The exceptions are the finalization block~$\ceu{\Fin{P}}$ and the
\texttt{@}-expressions which result from expansions in the transition rules to
be presented.

Regarding mismatches between the concrete and abstract languages, the concrete
\code{await} and \code{emit} primitives support communication of values between
them, e.g., an ``\code{emit a(10)}'' awakes a ``\code{v=await a}'' setting
variable~\code{v} to~10.
To reproduce this functionality in the formal semantics, we can use a shared
variable to hold the value of an $\ceu{\EmitInt}$ and access it after the
corresponding $\ceu{\AwaitInt}$ awakes.
%
Also, a ``\code{finalize $A$ with $B$ end; $C$}'' in the concrete language is
equivalent to ``\ceu{A;\;((\Fin{B})\ \Or\ C)}'' in the abstract language.
In the concrete language, $A$ and~$C$ execute in sequence, and
the finalization code~$B$ is implicitly suspended waiting for~$C$
termination.
In the abstract language, ``$\ceu{\Fin B}$'' suspends forever when reached (it is
an awaiting expression that never awakes).
Hence, we need an explicit \code{or} to execute~$C$ in parallel, whose
termination aborts ``$\ceu{\Fin B}$'', which finally causes~$B$ to
execute (by the semantic rules to be discussed).

\subsection{Operational Semantics}

The core of our semantics describes how a program reacts to a single external
input event, i.e., starting from an input event, how the program behaves and
becomes idle again to proceed to a subsequent reaction.
%
We use a set of small-step operational rules~\cite{Plotkin-G-D-1981} which
are designed in such a way that at most one transition is possible at any
time, resulting in deterministic reactions.
%
The transition rules map a triple with a program~$p$, a stack level~$n$, and an
emitted event~$e$ to a modified triple as follows:
\[
  \<p,n,e>\trans\<p',n',e'>\,,
\]
where~$p,p'\in\P$ are abstract-language programs, $n,n'\in\N$ are nonnegative
integers representing the current stack level, and~$e,e'\in\E\cup\{\nil\}$ are
the events emitted before and after the transition (both possibly being the
empty event~$\nil$).
$\E$ is a set of primitive events.

We will refer to the triples on the left-hand and right-hand sides of
symbol~$\trans$ as \emph{descriptions} (denoted~$\delta$).  The triple on the
left-hand side of symbol~$\trans$ is called the \emph{input description}, and
the triple on its right-hand side is called the \emph{output description}.

%-
% \begin{align*}
% p, p' &\in\P
%     && (program~as~described~in~Listing~\ref{lst.formal.syntax})
% \\
% n, n' &\in\N
%     && (current~stack~level)
% \\
% e, e' &\in\E \cup \{\epsilon\}
%     && (emitted~event,~possibly~none)
% \end{align*}
%-

At the beginning of a reaction to an input event~$id$, the input description is
initialized with stack level~0 ($n=0$) and with the externally emitted event
($e=id$).
%, but \code{emitInt} expressions can increase the stack level.
At the end of a reaction, after an arbitrary but finite number of transitions,
the last output description will block with a (possibly) modified program~$p'$, at stack
level~0, and with no event emitted~($\nil$):
\[
  \<p,0,e>\mathbin{\trans[*]}\<p',0,\nil>\,.
\]

We distinguish between two types of transition rules:
    \emph{outermost transitions} $\out$ and
    \emph{nested transitions} $\nst$\,.

\subsubsection*{Outermost transitions}

The~$\out$ rules \R{push} and \R{pop} are non-recursive definitions that
apply to the program as a whole.  These are the only rules that manipulate
the stack level.
\begin{align*}
  &\AxiomC{$e\ne\nil$}
  \UnaryInfC{$\<p,n,e>\out\<\bcast(p,e),n+1,\nil>$}
  \DisplayProof
  \Rtag{push}\\[\JOT]
  %%
  &\AxiomC{$n>0$}
  \AxiomC{$p=\ceu{\Nop,\Break}\vee\isblocked(p,n)$}
  \BinaryInfC{$\<p,n,\nil>\out\<p,n-1,\nil>$}
  \DisplayProof
  \Rtag{pop}
\end{align*}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \frac
%     { \DS e \neq \epsilon }
% %   -----------------------------------------------------------
%     { \DS \LL p,n,e \RR \OUT \LL bcast(p),n+1,\epsilon \RR }
%     & \textbf{(push)}   \\
% %%%
% & \frac
%     { \DS n>0, \2 ((p=@nop) \vee isblocked(n,p)) }
% %   -----------------------------------------------------------
%     { \DS \LL p,n,\epsilon \RR \OUT \LL p,n-1,\epsilon \RR }
%     & \textbf{(pop)}    \\
% %%%
% %& \LL p,0,\epsilon \RR \1\xrightarrow\1 \bot
%     %& \textbf{(end)}    %\\
% \end{eqnarray*}
% }
%-

Rule \R{push} matches whenever there is an emitted event in the input
description,
and instantly broadcasts the event to the program, which means
    (a)~awaking active $\ceu{\AwaitExt}$ or $\ceu{\AwaitInt}$ expressions altogether (see function~$\bcast$ in
        Figure~\ref{fig.bcast}),
    (b)~creating a nested reaction by increasing the stack level, and, at the same time,
    (c)~consuming the event ($e$ becomes~$\nil$).
%
Rule \R{push} is the only rule in the semantics that matches an
emitted event and also immediately consumes it.

Rule \R{pop} only decreases the stack level, not affecting the
program, and only applies if the program is blocked (see function~$\isblocked$ in
Figure~\ref{fig.isblocked}).
This condition ensures that an $\ceu{\EmitInt}$ only resumes after its internal
reaction completes and blocks in the current stack level.

At the beginning of a reaction, an external event is emitted, which
will trigger rule \R{push}, which will immediately raise the stack level
to~1.
At the end of the reaction, the program will block or terminate and
successive applications of
rule~\R{pop} will eventually lead to a description containing this
same program at stack level~0.

\subsubsection*{Nested transitions}

The~$\nst$ rules are recursive definitions of the form
\[
\<p,n,\nil>\nst\<p',n,e>.
\]
%
%-
% \begin{align*}
% \LL p, n,\epsilon \RR &\NST
% \LL p',n,e        \RR
%     & \textbf{(rule-inner)}
% \end{align*}
%-
%
Nested transitions do not affect the stack level and never have an emitted
event as a precondition.  The distinction between~$\out$ and~$\nst$ prevents
rules \R{push} and \R{pop} from matching and, consequently, from
inadvertently modifying the current stack level before the nested reaction
is complete.

A complete reaction consists of a series of transitions of the form
\begin{align*}
  \<p,0,e_\ext>\outpush\<p_1,1,\nil>
  \Big[\null\nst[*]\null\out\null\Big]\!\!\ast
  \null\nst[*]\null\outpop\<p',0,\nil>\,.
\end{align*}
%
%-
% \begin{align*}
% a) &\5\5
%     \LL p,0,ext \RR
%         \1\xrightarrow[out]{push}\1
%     \LL q,1,\epsilon \RR
% \\
% b) &\5\5 \1[ \1\xrightarrow[in]{*}\1
%     \LL r,i,e \RR
%         \1\xrightarrow[out]\1
%     \LL s,j,\epsilon \RR \1]*
% \\
% c) &\5\5 \1\xrightarrow[in]{*}\1
%     \LL t,k,\epsilon \RR
%         \1\xrightarrow[out]{pop}\1
%     \LL u,0,\epsilon \RR
% \end{align*}
%-
%
First, a~$\outpush$ starts a nested reaction at level~1.
Then, a series of alternations between zero or more~$\nst$ transitions (nested reactions) and a
single~$\out$ transition (stack operation) takes place.
Finally, a last~$\outpop$ transition decrements the
stack level to~0 and terminates the reaction.

The~$\nst$ rules for atoms are defined as follows:
\begin{align*}
  \<\ceu{\Mem(\Id)},n,\nil>
  &\nst\<\ceu{\Nop},n,\nil>\Rtag{mem}\\[\JOT]
  %%
  \<\ceu{\EmitInt(\Id)},n,\nil>
  &\nst\<\ceu{\CanRun(n)},n,\ceu{\Id}>\Rtag{emit-int}\\[\JOT]
  %%
  \<\ceu{\CanRun(n)},n,\nil>
  &\nst\<\ceu{\Nop},n,\nil>\Rtag{can-run}
\end{align*}

%-
% { \setlength{\jot}{20pt}
% \begin{align*}
% \LL mem(id), n, \epsilon \RR &\NST
% \LL @nop, n, \epsilon \RR
%     & \textbf{(mem)}        \\
% %%%
% \LL emit(id), n, \epsilon \RR &\NST
% \LL @canrun(n), n, id \RR
%     & \textbf{(emitInt)}    \\
% %%%
% \LL @canrun(n), n, \epsilon \RR &\NST
% \LL @nop, n, \epsilon \RR
%     & \textbf{(canrun)}     \\
% \end{align*}
% }
%-

A $\ceu{\Mem}$ operation becomes a $\ceu{\Nop}$ which indicates the memory
access (rule \R{mem}).
An $\ceu{\EmitInt(id)}$ generates an event $\ceu{\Id}$ and transits to a
$\ceu{\CanRun(n)}$ which can only resume at level~$n$ (rule \R{emit-int}).
Since all~$\nst$ rules can only transit with $e=\nil$, an $\ceu{\EmitInt}$
inevitably causes rule \R{push} to execute at the outer level, creating a new
level~$n+1$ on the stack.
Also, with the new stack level, the resulting $\ceu{\CanRun}(n)$ itself cannot
transit yet (rule~\R{can-run}), providing the desired stack-based semantics for
internal events.

The rules for conditionals and sequences are straightforward:
%
\begin{gather*}
  \AxiomC{$\eval(\ceu{\Mem(\Id)})$}
  \UnaryInfC{$\<\ceu{\IfElse{\Mem(\Id)}{p}{q}},n,\nil>\nst\<p,n,\nil>$}
  \DisplayProof
  \Rtag{if-true}\\[\JOT]
  %%
  \AxiomC{$\lnot\eval(\ceu{\Mem(\Id)})$}
  \UnaryInfC{$\<\ceu{\IfElse{\Mem(\Id)}{p}{q}},n,\nil>\nst\<q,n,\nil>$}
  \DisplayProof
  \Rtag{if-false}\\[\JOT]
  %%
  \AxiomC{$\<p,n,\nil>\nst\<p',n,e>$}
  \UnaryInfC{$\<\ceu{p\,;\,q},n,\nil>\nst\<\ceu{p';\,q},n,e>$}
  \DisplayProof
  \Rtag{seq-adv}
\end{gather*}
\vskip-\belowdisplayskip
\vskip-\abovedisplayskip
\vskip\JOT
\begin{align*}
  \<\ceu{\Nop;\,q},n,\nil>&\nst\<q,n,\nil>\Rtag{seq-nop}\\[\JOT]
  %%
  \<\ceu{\Break;\,q},n,\nil>&\nst\<\ceu{\Break},n,\nil>\Rtag{seq-brk}
\end{align*}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \frac
%     { \DS val(id) \neq 0 }
% %   -----------------------------------------------------------
%     { \DS \LL (if~mem(id)~then~p~else~q),n,\epsilon \RR \NST
%           \LL p, n, \epsilon \RR }
%     & \textbf{(if-true)}       \\
% %%%
% & \frac
%     { \DS val(id,n) = 0 }
% %   -----------------------------------------------------------
%     { \DS \LL (if~mem(id)~then~p~else~q),n,\epsilon \RR \NST
%           \LL q,n,\epsilon \RR }
%     & \textbf{(if-false)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~;~q), n, \epsilon \RR \NST \LL (p'~;~q), n, e \RR }
%     & \textbf{(seq-adv)}      \\
% %%%
% & \LL (@nop~;~q),n,\epsilon \RR \NST  \LL q,n,\epsilon \RR
%     & \textbf{(seq-nop)}      \\
% %%%
% & \LL (break~;~q),n,\epsilon \RR \NST \LL break,n,\epsilon \RR
%     & \textbf{(seq-brk)}
% \end{eqnarray*}
% }
%-

Given that our semantics focuses on control, rules \R{if-true} and
\R{if-false} are the only to query~$\ceu{\Mem}$ expressions.
%
Function~$\eval$ evaluates a given~$\ceu{\Mem}$ expression to a boolean value.
%
%Although the value here is arbitrary, it is unique in a reaction, because a
%given expression can execute only once within it (remember that $loops$ must
%contain $awaits$ which, from rule \textbf{await}, cannot awake in the same
%reaction they are reached).
%For all other rules, we omit these values (e.g., \textbf{seq-nop}).

%As determined for nested rules, compound expressions also can only have
%$\epsilon$ as a precondition and they never modify $n$.
%However, they can still emit an event to nest another reaction.
%For instance, in rule \textbf{seq-adv}, if the sub-expression $p$ emits event
%$e$, the whole composition also emits $e$.
%However, rules \textbf{push} and \textbf{pop} can only match at the outermost
%level.

The rules for loops are similar to those for sequences, but use ``\code{@}''
as separators to bind breaks to their enclosing loops:
\begin{align*}
  \<\ceu{\Loop{p}},n,\nil>
  &\nst\<\ceu{p\AtLoop{p}},n,\nil>\Rtag{loop-expd}\\[\JOT]
  %%
  &\hskip-6.35em
  \AxiomC{$\<q,n,\nil>\nst\<q',n,e>$}
  \UnaryInfC{$\<\ceu{q\AtLoop{p}},n,\nil>\nst\<\ceu{q'\AtLoop{p}},n,e>$}
  \DisplayProof
  \Rtag{loop-adv}\\[\JOT]
  %%
  \<\ceu{\Nop\AtLoop{p}},n,\nil>
  &\nst\<\ceu{\Loop{p}},n,\nil>\Rtag{loop-nop}\\[\JOT]
  %%
  \<\ceu{\Break\AtLoop{p}},n,\nil>
  &\nst\<\ceu{\Nop},n,\nil>\Rtag{loop-brk}
\end{align*}

%-
% %
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (loop~p),n,\epsilon \RR \NST \LL (p~@loop~p), n, \epsilon \RR
%     & \textbf{(loop-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% % -----------------------------------------------------------
%     { \DS \LL (p~@loop~q),n,\epsilon \RR \NST \LL (p'~@loop~q), n, e \RR }
%     & \textbf{(loop-adv)}    \\
% %%%
% & \LL (@nop~@loop~p), n, \epsilon \RR \NST \LL (loop~p), n, \epsilon \RR
%     & \textbf{(loop-nop)}    \\
% %%%
% & \LL (break~@loop~p), n, \epsilon \RR \NST \LL @nop, n, \epsilon \RR
%     & \textbf{(loop-brk)}
% \end{eqnarray*}
% }
%-

When a program encounters a $\ceu{\Loop}$, it first expands its body in sequence with
itself (rule \R{loop-expd}).
Rules \R{loop-adv} and \R{loop-nop} are similar to rules
\R{seq-adv} and \R{seq-nop}, advancing the loop until a~$\ceu{\Nop}$ is reached.
However, what follows the loop is the loop itself (rule \R{loop-nop}).
Note that if we used ``\code{;}'' as a separator in loops, rules
\R{loop-brk} and \R{seq-brk} would conflict.
%
Rule \R{loop-brk} escapes the enclosing loop, transforming everything into
a~$\ceu{\Nop}$.
%Rule \textbf{loop-brk} escapes the enclosing loop, transforming everything
%into a $clear(p)$.
%We cannot simply transform the loop into a $nop$ because its body may be a
%parallel composition containing finalization blocks.

The rules for~$\ceu{\And}$ and~$\ceu{\Or}$ compositions ensure that the
left-hand side of compositions always transition before their right-hand
side:
%%
\begin{gather*}
  \hskip-.9em
  \<\ceu{p\And{q}},n,\nil>
  \nst\<\ceu{p\AtAnd(\CanRun(n);q)},n,\nil>
  \Rtag{and-expd}\\[\JOT]
  %%
  \AxiomC{$\<p,n,\nil>\nst\<p',n,e>$}
  \UnaryInfC{$\<\ceu{p\AtAnd{q}},n,\nil>\nst\<\ceu{p'\AtAnd{q}},n,e>$}
  \DisplayProof
  \Rtag{and-adv1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \AxiomC{$\<q,n,\nil>\nst\<q',n,e>$}
  \BinaryInfC{$\<\ceu{p\AtAnd{q}},n,\nil>\nst\<\ceu{p\AtAnd{q'}},n,e>$}
  \DisplayProof
  \Rtag{and-adv2}
\end{gather*}

\begin{gather*}
  \<\ceu{p\Or{q}},n,\nil>
  \nst\<\ceu{p\AtOr(\CanRun(n);q)},n,\nil>
  \Rtag{or-expd}\\[\JOT]
  %%
  \AxiomC{$\<p,n,\nil>\nst\<p',n,e>$}
  \UnaryInfC{$\<\ceu{p\AtOr{q}},n,\nil>\nst\<\ceu{p'\AtOr{q}},n,e>$}
  \DisplayProof
  \Rtag{or-adv1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \AxiomC{$\<q,n,\nil>\nst\<q',n,e>$}
  \BinaryInfC{$\<\ceu{p\AtOr{q}},n,\nil>\nst\<\ceu{p\AtOr{q'}},n,e>$}
  \DisplayProof
  \Rtag{or-adv2}
\end{gather*}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (p~and~q),n,\epsilon \RR \NST \LL (p~@and~(@canrun(n)~;~q)),n,\epsilon \RR
%     & \textbf{(and-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~q),n,\epsilon \NST \LL (p'~@and~q),n,e \RR }
%     & \textbf{(and-adv1)}      \\
% %%%
% & \frac
%     { \DS isblocked(n,p) \1,\2 \LL q,n,\epsilon \RR \NST \LL q',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~q),n,\epsilon \RR \NST \LL (p~@and~q'), n, e \RR }
%     & \textbf{(and-adv2)}      \\
% %%%
% & \LL (p~or~q), n, \epsilon \RR \NST \LL (p~@or~(@canrun(n)~;~q)), n, \epsilon \RR
%     & \textbf{(or-expd)}       \\
% %%%
% & \frac
%     { \DS \LL p,n,\epsilon \RR \NST \LL p',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~q),n,\epsilon \RR \NST \LL (p'~@or~q), n, e \RR }
%     & \textbf{(or-adv1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) \1,\2 \LL q,n,\epsilon \RR \NST \LL q',n,e \RR }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~q),n,\epsilon \RR \NST \LL (p~@or~q'), n, e \RR }
%     & \textbf{(or-adv2)}   %\\
% \end{eqnarray*}
% }
%-

Rules~\R{and-expd} and~\R{or-expd} insert a~$\ceu{\CanRun(n)}$ at the beginning
of the right branch.
This ensures that~any $\ceu{\EmitInt}$ on the left branch, which transits to
a~$\ceu{\CanRun(n)}$, still resumes before the right branch starts.
%
The deterministic behavior of the semantics relies on the \emph{isblocked}
predicate (see Figure~\ref{fig.isblocked}) which appears in rules
\R{and-adv2} and \R{or-adv2}.
These rules require the left branch~$p$ to be blocked for the
right branch to transition from~$q$ to~$q'$.

In a parallel~$\ceu{\AtAnd}$, if one of the sides terminates, the composition is
simply substituted by the other side (rules \R{and-nop1} and
\R{and-nop2} below).
%
In a parallel~$\ceu{\AtOr}$, however, if one of the sides terminates, the
whole composition
terminates and function~$\clear$ is used to properly finalize the aborted
side (rules \R{or-nop1} and \R{or-nop2}).
\begin{gather*}
  \<\ceu{{\Nop}\AtAnd{q}},n,\nil>\nst\<q,n,\nil>\Rtag{and-nop1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtAnd{\Nop}},n,\nil>\nst\<p,n,\nil>$}
  \DisplayProof
  \Rtag{and-nop2}\\[\JOT]
  %%
  \<\ceu{{\Nop}\AtOr{q}},n,\nil>\nst\<\clear(q),n,\nil>\Rtag{or-nop1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtOr{\Nop}},n,\nil>\nst\<\clear(p),n,\nil>$}
  \DisplayProof
  \Rtag{or-nop2}
\end{gather*}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (@nop~@and~q), n, \epsilon \RR \NST \LL q,n,\epsilon \RR
%     & \textbf{(and-nop1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~@nop), n, \epsilon \RR \NST \LL p,n,\epsilon \RR }
%     & \textbf{(and-nop2)}   \\
% %%%
% & \LL (@nop~@or~q), n, \epsilon \RR \NST \LL clear(q),n,\epsilon \RR
%     & \textbf{(or-nop1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~@nop), n, \epsilon \RR \NST \LL clear(p),n,\epsilon \RR }
%     & \textbf{(or-nop2)}   %\\
% \end{eqnarray*}
% }
%-

The~$\clear$ function (see Figure~\ref{fig.clear}) concatenates all
active~$\ceu{\Fin}$ bodies of the side being aborted, so that they execute before the
composition rejoins.
Note that there are no transition rules for~$\ceu{\Fin}$ expressions.
This is because once reached, a $\ceu{\Fin}$ expression halts and will only execute
when it is aborted by a parallel trail and is expanded by the~$\clear$
function.
%In Section~\ref{sec.formal.fins}, we show how to map a finalization block in
%the concrete language to a $fin$ in the formal semantics.
%
Note also that there is a syntactic restriction that postulates that~$\ceu{\Fin}$ bodies cannot
contain awaiting expressions ($\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\Every}$, or $\ceu{\Fin}$),
i.e., the result of a~$\clear$ call is guaranteed to execute entirely within a reaction.

Finally, a~$\ceu{\Break}$ in one of the sides in parallel escapes the closest
enclosing~$\ceu{\Loop}$, properly aborting the other side with the~$\clear$
function:
\begin{gather*}
  \hskip-.5em
  \<\ceu{{\Break}\AtAnd{q}},n,\nil>\nst\<\ceu{\clear(q);\Break},n,\nil>
  \Rtag{and-brk1}\\[\JOT]
  %%
  \hskip-.5em
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtAnd{\Break}},n,\nil>
    \nst\<\ceu{\clear(p);\Break},n,\nil>$}
  \DisplayProof
  \Rtag{and-brk2}\\[\JOT]
  %%
  \<\ceu{{\Break}\AtOr{q}},n,\nil>\nst\<\ceu{\clear(q);\Break},n,\nil>
  \Rtag{or-brk1}\\[\JOT]
  %%
  \AxiomC{$\isblocked(p,n)$}
  \UnaryInfC{$\<\ceu{p\AtOr{\Break}},n,\nil>
    \nst\<\ceu{\clear(p);\Break},n,\nil>$}
  \DisplayProof
  \Rtag{or-brk2}
\end{gather*}

%-
% { \setlength{\jot}{20pt}
% \begin{eqnarray*}
% & \LL (break~@and~q), n, \epsilon \RR \NST \LL (clear(q)~;~break),n,\epsilon \RR
%     & \textbf{(and-brk1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@and~break), n, \epsilon \RR \NST \LL (clear(p)~;~break),n,\epsilon \RR }
%     & \textbf{(and-brk2)}   \\
% %%%
% & \LL (break~@or~q),n,\epsilon \RR \NST \LL (clear(q)~;~break),n,\epsilon \RR
%     & \textbf{(or-brk1)}   \\
% %%%
% & \frac
%     { \DS isblocked(n,p) }
% %   -----------------------------------------------------------
%     { \DS \LL (p~@or~break),n,\epsilon \RR \NST \LL (clear(p)~;~break),n,\epsilon \RR }
%     & \textbf{(or-brk2)}   %\\
% \end{eqnarray*}
% }
%-

A reaction eventually blocks in~$\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$,
$\ceu{\Every}$, $\ceu{\Fin}$, and~$\ceu{\CanRun}$ expressions in parallel
trails.
%
Then, if none of the trails is blocked in~$\ceu{\CanRun}$ expressions, it means
that the program cannot advance in the current reaction.
%
However, $\ceu{\CanRun}$ expressions can still resume at lower stack indexes
and will eventually resume in the current reaction (see rule \R{pop}).

\begin{figure}[h]
\small
\begin{gather*}
  \boxed{
    \begin{align*}
      %%
      %%-
      \intertext{\llap{(i)~}Function~$\bcast$:}
      %%-
      %%
      \bcast(\ceu{\AwaitExt(e)},e)
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \bcast(\ceu{\AwaitInt(e)},e)
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \bcast(\ceu{\Every{e}\ {p}},e)
      &=\ceu{p;\,\Every{e}\ {p}}\\[-1\jot]
      %%
      \bcast(\ceu{\CanRun(n)},e)
      &=\ceu{\CanRun(n)}\\[-1\jot]
      %%
      \bcast(\ceu{\Fin{p}},e)
      &=\ceu{\Fin{p}}\\[-1\jot]
      %%
      \bcast(\ceu{p;\,q},e)
      &=\ceu{\bcast(p,e);\,q}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtLoop{q}},e)
      &=\ceu{\bcast(p,e)\AtLoop{q}}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtAnd{q}},e)
      &=\ceu{{\bcast(p,e)}\AtAnd{\bcast(q,e)}}\\[-1\jot]
      %%
      \bcast(\ceu{p\AtOr{q}},e)
      &=\ceu{{\bcast(p,e)}\AtOr{\bcast(q,e)}}\\[-1\jot]
      %%
      bcast(\_,e)
      &=\_\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
      \\[1\jot]
      %%
      %%-
      \intertext{\llap{(ii)~}Predicate~$\isblocked$:}
      %%-
      %%
      \isblocked(\ceu{\AwaitExt(e)},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\AwaitInt(e)},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\Every{e}\ {p}},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{\CanRun(m)},n)
      &=(n>m)\\[-1\jot]
      %%
      \isblocked(\ceu{\Fin{p}},n)
      &=\mathit{true}\\[-1\jot]
      %%
      \isblocked(\ceu{p;\,q},n)
      &=\isblocked(p,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtLoop{q}},n)
      &=\isblocked(p,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtAnd{q}},n)
      &=\isblocked(p,n)\land\isblocked(q,n)\\[-1\jot]
      %%
      \isblocked(\ceu{p\AtOr{q}},n)
      &=\isblocked(p,n)\land\isblocked(q,n)\\[-1\jot]
      %%
      \isblocked(\_,n)
      &=\mathit{false}\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
        \\[1\jot]
      %%
      %%-
      \intertext{\llap{(iii)~}Function~$\clear$:}
      %%-
      %%
      \clear(\ceu{\AwaitExt(e)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\AwaitInt(e)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\Every{e}\ p})
      %%
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\CanRun(n)})
      &=\ceu{\Nop}\\[-1\jot]
      %%
      \clear(\ceu{\Fin{p}})
      &=p\\[-1\jot]
      %%
      \clear(\ceu{p;\,q})
      &=\clear(p)\\[-1\jot]
      %%
      \clear(\ceu{p\AtLoop{q}})
      &=\clear(p)\\[-1\jot]
      %%
      \clear(\ceu{p\AtAnd{q}})
      &=\ceu{\clear(p);\,\clear(q)}\\[-1\jot]
      %%
      \clear(\ceu{p\AtOr{q}})
      &=\ceu{\clear(p);\,\clear(q)}\\[-1\jot]
      %%
      \clear(\_)
      &=\xi\enspace
        (\ceu{\Mem},\ceu{\EmitInt},\ceu{\Break},\\[-1\jot]
      &\quad\ceu{\IfElse{}{}},\ceu{\Loop},\ceu{\And},\ceu{\Or},\ceu{\Nop})
    \end{align*}}
\end{gather*}
\vskip-2\belowdisplayskip
\caption{%
  (i)~Function~$\bcast$ awakes awaiting trails matching the event by
  converting~$\ceu{\protect\AwaitExt}$ and~$\ceu{\protect\AwaitInt}$
  to~$\ceu{\protect\Nop}$, and by unwinding $\ceu{\protect\Every}$
  expressions.
  %%
  \space(ii)~Predicate~$\isblocked$ is true only if all branches in parallel
  are blocked waiting for events, finalization clauses, or certain
  stack levels.
  %%
  \space(iii)~Function~$\clear$ extracts~$\ceu{\protect\Fin}$ expressions in
  parallel and put their bodies in sequence.
  %%
  In~(i), (ii), and~(iii),~``$\_$'' denotes the omitted cases and~``$\xi$''
  denotes the empty string.
  %%
}
\label{fig.bcast}
\label{fig.isblocked}
\label{fig.clear}
\end{figure}

%-
% {\small
% \begin{align*}
%   bcast(e, awaitExt(e)) &= @nop                         \\
%   bcast(e, awaitInt(e)) &= @nop                         \\
%   bcast(e, every~e~p)   &= p;~every~e~p                 \\
%   bcast(e, @canrun(n))  &= @canrun(n)                   \\
%   bcast(e, fin~p)       &= fin~p                        \\
%   bcast(e, p~;~q)       &= bcast(e,p)~;~q               \\
%   bcast(e, p~@loop~q)   &= bcast(e,p)~@loop~q           \\
%   bcast(e, p~@and~q)    &= bcast(e,p)~@and~bcast(e,q)   \\
%   bcast(e, p~@or~q)     &= bcast(e,p)~@or~bcast(e,q)    \\
%   bcast(e, \_)          &= \bot \2 (mem,emitInt,break,if,  \\
%                                  & \5\5 loop,and,or,@nop) %\\
% \end{align*}
% }
%-

%
%-
% {\small
% \begin{align*}
%   isblocked(n, \1 awaitExt(id)) &= true                                   \\
%   isblocked(n, \1 awaitInt(id)) &= true                                   \\
%   isblocked(n, \1 every~e~p)    &= true                                   \\
%   isblocked(n, \1 @canrun(m))   &= (n > m)                                \\
%   isblocked(n, \1 fin~p)        &= true                                   \\
%   isblocked(n, \1 p~;~q)        &= isblocked(n,p)                         \\
%   isblocked(n, \1 p~@loop~q)    &= isblocked(n,p)                         \\
%   isblocked(n, \1 p~@and~q)     &= isblocked(n,p) \wedge isblocked(n,q)   \\
%   isblocked(n, \1 p~@or~q)      &= isblocked(n,p) \wedge isblocked(n,q)   \\
%   isblocked(n, \1 \_)           &= false \2 (mem,emitInt,break,if,        \\
%                                 & \5\5\5\1 loop,and,or,@nop)   %\\
% \end{align*}
% }
%-

%-
% {\small
% \begin{align*}
%   clear( awaitExt(e) ) &= @nop                  \\
%   clear( awaitInt(e) ) &= @nop                  \\
%   clear( every~e~p )   &= @nop                  \\
%   clear( @canrun(n) )  &= @nop                  \\
%   clear( fin~p )       &= p                     \\
%   clear( p~;~q )       &= clear(p)              \\
%   clear( p~@loop~q )   &= clear(p)              \\
%   clear( p~@and~q )    &= clear(p)~;~clear(q)   \\
%   clear( p~@or~q )     &= clear(p)~;~clear(q)   \\
%   clear( \_ )          &= \bot \2 (mem,emitInt,break,if, \\
%                                   & \5\5 loop,and,or,@nop) %\\
% \end{align*}
% }
%-


\subsection{Properties}


\subsubsection{Determinism}

Transitions~$\out$ and~$\nst$ are defined in such a way that given an input
description either no rule is applicable or exactly one of them can be
applied.  This means that the resulting relation~$\trans$ is in fact a
partial function.

The next two lemmas establish the determinism of a single application
of~$\out$ and~$\nst$.  Lemma~\ref{lem.x.det-out} follows from a simple
inspection of rules~\R{push} and~\R{pop}.  The proof of
Lemma~\ref{lem.x.det-nst}, however, requires an induction on the structure
of the derivation trees produced by the rules for~$\nst$.  Both lemmas are
used in the proof of Theorem~\ref{thm.x.det}, the main result of this
section.  Theorem~\ref{thm.x.det} establishes that any given number of
applications of~$\trans$ starting from the same input description will
always lead to the same output description.

\begin{lemma}
  \label{lem.x.det-out}
  %%
  If~$\delta\out\delta_1$ and~$\delta\out\delta_2$ then~$\delta_1=\delta_2$.
\end{lemma}

\begin{lemma}
  \label{lem.x.det-nst}
  %%
  If~$\delta\nst\delta_1$ and~$\delta\nst\delta_2$ then~$\delta_1=\delta_2$.
\end{lemma}

\begin{theorem}[Determinism]
  \label{thm.x.det}\strut\\
  %%
  If~$\delta\trans[i]\delta_1$ and~$\delta\trans[i]\delta_2$
  then~$\delta_1=\delta_2$.
\end{theorem}
\begin{proof}
  By induction on~$i$.  The theorem is trivially true if~$i=0$ and follows
  directly from the lemmas if~$i=1$.  Suppose
  \[
    \delta\trans[1]\delta_1'\trans[i-1]\delta_1
    \quad\text{and}\quad
    \delta\trans[1]\delta_2'\trans[i-1]\delta_2\,,
  \]
  for some~$i>1$, $\delta_1'$ and~$\delta_2'$.
  %%
  Then, by Lemma~\ref{lem.x.det-out} or~\ref{lem.x.det-nst}, depending on
  whether the first transition is~$\out$ or~$\nst$ (it cannot be both),
  $\delta_1'=\delta_2'$, and by the induction hypothesis,
  $\delta_1=\delta_2$.
\end{proof}

% The proof for determinism relies on the fact all semantic rules are
% mutually exclusive, i.e., their preconditions are unique in the set of
% rules.  This can be verified by direct inspection of rules.

% Rule \textbf{push} is the only one with $e \neq \epsilon$ as a
% precondition, and is trivially mutually exclusive with all other rules.

% Rule \textbf{pop} either has $p=@nop$ or $isblocked(p,n)$ as
% preconditions.
% %
% Note that rule \textbf{pop} only applies syntactically to top-level
% transitions.  For instance, it can never match $\NST$ rules for
% subprograms as in rule \textbf{seq-adv}.
% %
% Hence, for the first case, rule \textbf{pop} only applies, and is the only
% one to apply, to $nop$ as the whole program (i.e., a $nop$ not surrounded
% by other expressions, such as in rule \textbf{seq-nop}).
% %
% For the second case, we need to show that given $\LL p,n,\epsilon \RR$, no
% $\NST$ transitions apply with $isblocked(p,n)$ and vice versa.  Except for
% $@canrun$, there are no $\NST$ transitions for the other blocking
% expressions ($awaitExt$, $awaitInt$, $every$, and $fin$).  However,
% considering the precondition $\LL p,n,\epsilon \RR$,
% $isblocked(@canrun(n),n)$ is false.  Hence, given the preconditions for
% rule \textbf{pop}, no $\NST$ transitions can occur.  Conversely, if a
% $\NST$ transition is possible, then $isblocked(p,n)$ must be false.
% Again, except for $@canrun$, all other transitions do not involve blocking
% expressions, hence, for these transitions, $isblocked(p,n)$ must be false.
% For rule \R{can-run}, a transition can only occur if the current stack
% level matches $@canrun(n)$.  In this case, $isblocked(@canrun(n),n)$ is
% false.

% Finally, we need to show that $\NST$ transitions are mutually exclusive
% among themselves.
% %
% Note that most rules have unique syntactic prefixes, e.g., $(@nop~@and~q)$
% (rule \textbf{and-nop1}) is trivially mutually exclusive with
% $(@nop~@loop~p)$ (rule \textbf{or-nop1}).
% %
% The only exceptions are rules \textbf{and-adv1} vs. \textbf{and-adv2}, and
% \textbf{or-adv1} vs. \textbf{or-adv2}.  In both cases, we need to show
% that if the left branch can advance, then it cannot be blocked and
% vice-versa, i.e., that $\LL p,n,\epsilon \RR \NST \LL p',n,e \RR$ and
% $isblocked(p,n)$ are mutually exclusive, which is exactly the same
% reasoning for rule \textbf{pop} above.


\subsubsection{Termination}

In this section, we prove that any sufficiently long sequence of
applications of~$\trans$ will lead to an irreducible description, i.e., one
that cannot be modified by further transitions.  Before doing that, however,
we need to introduce some notation and establish some basic properties
of~$\nst$ and~$\out$.

\begin{definition}
  \label{def.x.Hnst}
  %%
  A description~$\delta=\<p,n,e>$ is \emph{nested-irre\-ducible}
  iff~$e\ne\nil$ or~$p=\ceu{\Nop},\ceu{\Break}$ or~$\isblocked(p,n)$~is
  true.
\end{definition}

Nested-irreducible descriptions serve as normal forms for~$\nst$
transitions: they embody the result of an exhaustive number of~$\nst$
applications.  We will write~$\delta_\Hnst$ to indicate that
description~$\delta$ is nested-irreducible.

The use of qualifier ``irreducible'' in Definition~\ref{def.x.Hnst} is
justified by Proposition~\ref{prop.x.irr-nst-i}.  The proposition
establishes that if a finite number of applications of~$\nst$ results in an
irreducible description, then that occurs exactly once, at some specific
number~$i$.  The proof of the lemma follows directly from the definition
of~$\nst$ by contradiction on the hypothesis that there is such~$k\ne{i}$.

\begin{proposition}
  \label{prop.x.irr-nst-i}
  %%
  If~$\delta\nst[i]\delta_\Hnst'$ then, for all~$k\ne{i}$, there is
  no~$\delta_\Hnst''$ such that~$\delta\nst[k]\delta''_\Hnst$.
\end{proposition}

The next lemma establishes that sequences of~$\nst$ transitions behave
as expected regarding the order of evaluation of composition members.  Its
proof follows by induction on~$i$.

\begin{lemma}
  \label{lem.x.props-nst-i}\strut\\
  %%
  If~$\<p_1,n,e>\nst[i]\<p_1',n,e'>$, for any~$p_2$:
  \begin{enumerate}[(a)]
  \item\label{lem.x.props-nst-i.a}
    $\<\ceu{p_1;\,p_2},n,e>\nst[i]\<p_1';p_2,n,e'>$.
    %%
  \item\label{lem.x.props-nst-i.b}
    $\<\ceu{p_1\AtLoop{p_2}},n,e>\nst[i]\<\ceu{p_1'\AtLoop{p_2}},n,e'>$.
    %%
  \item\label{lem.x.props-nst-i.c}
    $\<\ceu{{p_1}\AtAnd{p_2}},n,e>\nst[i]\<\ceu{{p_1'}\AtAnd{p_2}},n,e'>$.
    %%
  \item\label{lem.x.props-nst-i.d}
    $\<\ceu{{p_1}\AtOr{p_2}},n,e>\nst[i]\<\ceu{{p_1}'\AtOr{p_2}},n,e'>$.
  \end{enumerate}
  \smallskip
  If~$\<p_2,n,e>\nst[i]\<p_2',n,e'>$, for any~$p_1$ such
  that~$\isblocked(p_1,n)$:
  \begin{enumerate}[(a)]
    \setcounter{enumi}{4}
  \item\label{lem.x.props-nst-i.e}
    $\<\ceu{{p_1}\AtAnd{p_2}},n,e>\nst[i]\<\ceu{{p_1}\AtAnd{p_2'}},n,e'>$.
    %%
  \item\label{lem.x.props-nst-i.f}
    $\<\ceu{{p_1}\AtOr{p_2}},n,e>\nst[i]\<\ceu{{p_1}\AtOr{p_2'}},n,e'>$.
  \end{enumerate}
\end{lemma}
%%
% \begin{proof}[Proof of~(a)]
%   By induction on~$i$.  The lemma is trivially true for~$i=0$,
%   as~$p_1=p_1'$, and follows directly from~\R{seq-adv} for~$i=1$.  Suppose
%   \begin{equation}
%     \label{lem.x.props-nst-i.a.eq1}
%     \<p_1,n,e>\nst[1]\<p_1'',n,e''>\nst[i-1]\<p_1',n,e'>\,,
%   \end{equation}
%   for some~$i>1$.  Then~$\<p_1'',n,e''>$ is not nested-irreducible, i.e.,
%   $e=\nil$ and~$p\ne{\ceu{\Nop},\ceu{\Break}}$ and~$\isblocked(p_1'',n)$
%   is false.  By~\eqref{lem.x.props-nst-i.a.eq1} and by~\R{seq-adv},
%   \begin{equation}
%     \label{lem.x.props-nst-i.a.eq2}
%     \<\ceu{p_1;\,p_2},n,e>\nst[1]\<\ceu{p_1'';\,p_2},n,e''>\,.
%   \end{equation}
%   From~\eqref{lem.x.props-nst-i.a.eq1}, by the induction hypothesis,
%   \begin{equation}
%     \label{lem.x.props-nst-i.a.eq3}
%     \<\ceu{p_1'';\,p_2},n,e''>\nst[i-1]\<\ceu{p_1';\,p_2},n,e'>\,.
%   \end{equation}
%   From~\eqref{lem.x.props-nst-i.a.eq2} and~\eqref{lem.x.props-nst-i.a.eq3},
%   \[
%     \<\ceu{p_1;\,p_2},n,e>\nst[i]\<\ceu{p_1';\,p_2},n,e'>\,.
%   \]
%   The proofs of the other cases are similar.
% \end{proof}
%%

The syntactic restrictions discussed in Section~\ref{sec.sem}, regarding the
body of~$\ceu{\Fin}$ and~$\ceu{\Loop}$ expressions, and their consequences,
are formalized in the next assumption.

\begin{assumption}[Syntactic restrictions]\strut
  \label{ass.x.syn-rest}
  %%
  \begin{enumerate}[(a)]
  \item\label{ass.x.syn-rest.fin} If~$p=\ceu{\Fin{p_1}}$ then~$p_1$ contains
    no occurrences of~$\ceu{\AwaitExt}$, $\ceu{\AwaitInt}$, $\ceu{\Every}$,
    or~$\ceu{\Fin}$ expressions.  Consequently, for any~$n$,
    $\<\clear(p_1),n,\nil>\nst[*]\<\ceu{\Nop},n,\nil>$.
    %%
    % \[
    %   \<\clear(p_1),n,\nil>\nst[*]\<\ceu{\Nop},n,\nil>\,.
    % \]
    %%
  \item\label{ass.x.syn-rest.loop} If~$p=\ceu{\Loop{p_1}}$ then all
    execution paths of~$p_1$ contain a matching~$\ceu{\Break}$ or
    an~$\ceu{\AwaitExt}$.  Consequently, for all~$n$, there are~$p_1'$
    and~$e$ such that
    $\<\ceu{\Loop{p_1}},n,\nil>\nst[*]\<p_1',n,e>$,
    %%
    % \[
    %   \<\ceu{\Loop{p_1}},n,\nil>\nst[*]\<p_1',n,e>\,,
    % \]
    %%
    where $p_1'=\ceu{{\Break}\AtLoop{p_1}}$ or~$\isblocked(p_1',n)$\,.
  \end{enumerate}
\end{assumption}

Theorem~\ref{thm.x.term-nst-*} establishes that a finite (possibly zero)
number of~$\nst$ transitions eventually leads to a nested-irreducible
description.  The proof is by induction on the structure of programs
(members of set~$P$) and uses Lemma~\ref{lem.x.props-nst-i} and
Assumption~\ref{ass.x.syn-rest}.

\begin{theorem}
  \label{thm.x.term-nst-*}
  %%
  For any~$\delta$ there is a~$\delta'_\Hnst$ such
  that~$\delta\nst[*]\delta'_\Hnst$.
\end{theorem}

The main result of this section, Theorem~\ref{thm.x.term}, is similar to
Theorem~\ref{thm.x.term-nst-*} but applies to transitions~$\trans$ in
general.  Before stating and proving it, we need to characterize irreducible
descriptions in general.  This characterization depends on the notions of
potency and rank.

\begin{definition}
  \label{def.x.pot}
  %%
  The \emph{potency} of a program~$p$ in reaction to event~$e$,
  denoted~$\pot(p,e)$, is the maximum number of~$\ceu{\EmitInt}$ expressions
  that can be executed during a reaction of~$p$ to~$e$.

  More formally, $\pot(p,e)=\pot'(\bcast(p,e))$ where~$\pot'$ is an
  auxiliary function that counts the maximum number of
  reachable~$\ceu{\EmitInt}$ expressions in the program resulting from the
  broadcast of event~$e$ to~$p$.

  The auxiliary function~$\pot'$ is defined by
  clauses~\eqref{def.x.pot.first}--\eqref{def.x.pot.last}:
  \begin{enumerate}[(a)]
  \item\label{def.x.pot.first}$\pot'(\ceu{\EmitInt}(e))=1$.
    %%
  \item$\pot'(\ceu{\IfElse{\Mem(\Id)}{p_1}{p_2}})
    =\max\{\pot'(p_1),\pot'(p_2)\}$.
    %%
  \item$\pot'(\ceu{\Loop{p_1}})=\pot'(p_1)$.
    %%
  \item$\pot'(\ceu{{p_1}\And{p_2}})=\pot'(p_1)+\pot'(p_2)$.
    %%
  \item$\pot'(\ceu{{p_1}\Or{p_2}})=\pot'(p_1)+\pot'(p_2)$.
    %%
  \item If~$p_1\ne\ceu{\Break},\ceu{\AwaitExt(e)}$,
    \begin{align*}
      \pot'(\ceu{p_1;\,p_2})&=\pot'(p_1)+\pot'(p_2)\\
      \pot'(\ceu{p_1\AtLoop{p_2}})&=
      \begin{cases}
        \pot'(p_1)              &\text{if\enspace(\dag)}\\
        \pot'(p_1)+\pot'(p_2)   &\text{otherwise,}\\
      \end{cases}
    \end{align*}
    where~(\dag) stands for: ``a~$\ceu{\Break}$ or~$\ceu{\AwaitExt}$ occurs
    in all execution paths of~$p_1$''.
    %%
  \item If~$p_1,p_2\ne\ceu{\Break}$.
    \[
      \pot'(\ceu{{p_1}\AtAnd{p_2}})=\pot'(p_1)+\pot'(p_2)\,.
    \]
    %%
  \item\label{def.x.pot.before-last} If~$p_1,p_2\ne\ceu{\Break}$
    and~$p_1,p_2\ne\ceu{\Nop}$,
    \[
      \pot'(\ceu{{p_1}\AtOr{p_2}})=\pot'(p_1)+\pot'(p_2)\,.
    \]
    %%
  \item\label{def.x.pot.last} Otherwise, if none
    of~\eqref{def.x.pot.first}--\eqref{def.x.pot.before-last} applies,
    $\pot(\_)=0$.
  \end{enumerate}
\end{definition}

\begin{definition}
  \label{def.x.rank}
  %%
  The \emph{rank} of a description~$\delta=\<p,n,e>$,
  denoted~$\rank(\delta)$, is a pair of nonnegative integers~$\<i,j>$ such
  that
  \begin{alignat*}{2}
    i&=\pot(p,e) &\quad\text{and}\quad
    j&=
       \begin{cases}
         n  &\text{if~$e=\nil$}\\
         n+1&\text{otherwise\,.}
       \end{cases}
  \end{alignat*}
\end{definition}

\begin{definition}
  \label{def.x.H}
  %%
  A description~$\delta$ is \emph{irreducible} (in symbols, $\delta_\#$) iff
  it is nested-irreducible and its~$\rank(\delta)$ is~$\<i,0>$, for
  some~$i\ge0$.
\end{definition}

An irreducible description~$\delta_\#=\<p,n,e>$ serves as a normal form for
transitions~$\trans$ in general.  Such description cannot be advanced
by~$\nst$, as it is nested-irreducible, and neither by~$\outpush$
nor~$\outpop$, as the second coordinate of its rank is~0, which
implies~$e=\nil$ and~$n=0$.

The next two lemmas establish that a single application of~$\out$ or~$\nst$
either preserves or decreases the rank of the input description.  All rank
comparisons assume lexicographic order, i.e., if~$\rank(\delta)=\<i,j>$
and~$\rank(\delta')=\<i',j'>$ then~$\rank(\delta)>\rank(\delta')$ iff~$i>i'$
or~$i=i$ and~$j>j'$.
%%
The proof of Lemma~\ref{lem.x.rank-out} follows directly from~\R{push}
and~\R{pop} and from Definitions~\ref{def.x.pot} and~\ref{def.x.rank}.  The
proof of Lemma~\ref{lem.x.rank-nst}, however, is by induction on the
structure of~$\nst$ derivations.  Since Lemma~\ref{lem.x.rank-nst} is of
fundamental importance for the termination result, we detail the proof of
one of its cases.

\begin{lemma}\strut
  \label{lem.x.rank-out}
  %%
  \begin{enumerate}[(a)]
  \item\label{lem.rank-out-push} If~$\delta\outpush\delta'$
    then~$\rank(\delta)=\rank(\delta')$.
  \item\label{lem.rank-out-pop} If~$\delta\outpop\delta'$
    then~$\rank(\delta)>\rank(\delta')$.
  \end{enumerate}
\end{lemma}

\begin{lemma}
  \label{lem.x.rank-nst}
  %%
  If~$\delta\nst\delta'$ then~$\rank(\delta)\ge\rank(\delta')$.
\end{lemma}
\begin{proof}
  By induction on the structure of~$\nst$ derivations.  Let
  \[
    \delta=\<p,n,e>
    \quad\text{and}\quad
    \delta'=\<p',n',e'>
  \]
  be descriptions with~$\rank(\delta)=\<i,j>$ and~$\rank(\delta')=\<i',j'>$
  such that~$\delta\nst\delta'$.  Then there is a derivation~$\pi$ whose
  conclusion is~$\delta\nst\delta'$, i.e.,
  $\pi\Vdash\<p,n,e>\nst\<p',n',e'>$.
  %%
  % \[
  %   \pi\Vdash\<p,n,e>\nst\<p',n',e'>\,.
  % \]
  %%
  By definition of~$\nst$, $e=\nil$ and~$n=n'$.  Depending on the structure
  of program~$p$, there are~11 distinct cases to be considered.  In each one
  of them, we need to show that~$\rank(\delta)\ge\rank(\delta')$.

  We proceed to prove the case where~$p=\ceu{{p_1}\AtLoop{p_2}}$, which
  itself consists of three subcases.
  \begin{case}
    $p_1=\ceu{\Nop}$.
    %%
    Then~$\pi$ is an instance of~\R{loop-nop}.  i.e., its conclusion is
    obtained by an application of this rule.  Hence~$p'=p_2$ and~$e'=\nil$.
    Thus
    \begin{align*}
        \rank(\delta)=\<\pot'(p_1)+\pot'(p_2),n>
                     \ge\<pot'(p_2),n>=\rank(\delta')\,.
    \end{align*}
  \end{case}
  \begin{case}
    $p_1=\ceu{\Break}$.
    %%
    Then~$\pi$ is an instance of~\R{loop-brk}.
    Hence~$p'=p_1$ and~$e'=\nil$.  Thus
    $\rank(\delta)=\rank(\delta')=\<0,n>$.
    %%
    % \[
    %   \rank(\delta)=\rank(\delta')=\<0,n>\,.
    % \]
    %%
  \end{case}
  \begin{case}
    $p_1\ne\ceu{\Nop},\ceu{\Break}$.
    %%
    Then~$\pi$ is an instance of~\R{loop-adv}.  Hence there is a
    derivation~$\pi'$ such that
    \begin{equation}
      \label{lem.x.rank-nst-eq1}
      \pi'\Vdash\<p_1,n,\nil>\nst\<p_1',n,e_1'>\,,
    \end{equation}
    for some~$p_1'$ and~$e_1'$.  Thus~$p'=\ceu{p_1'\AtLoop{\,p_2}}$
    and~$e'=e_1'$.

    There are two subcases.
    \begin{subcase}
      \label{lem.x.rank-nst-case1}
      $\pot'(p)=\pot'(p_1)$.
      %%
      Then, by Definition~\ref{def.pot}, every execution path of~$p_1$
      contains a (matching)~$\ceu{\Break}$ or~$\ceu{\AwaitExt}$ expression.
      A single~$\nst$ cannot terminate the loop, since~$p_1\ne\ceu{\Break}$,
      nor it can consume an~$\ceu{\AwaitExt}$, which means that all
      execution paths in~$p_1'$ still contain a~$\ceu{\Break}$
      or~$\ceu{\AwaitExt}$.  Hence~$\pot'(p')=\pot'(p_1')$.

      There are two subcases.
      \begin{subsubcase}
        $e'=\nil$.
        %%
        Then $\rank(\delta)=\<pot'(p_1),n>$ and
        $\rank(\delta')=\<pot'(p_1'),n>$.  From~\eqref{lem.x.rank-nst-eq1},
        by the induction hypothesis, $\pot'(p_1)\ge\pot(p_1')$.  Thus
        $\rank(\delta)\ge\rank(\delta')$.
        %%
        % \[
        %   \rank(\delta)\ge\rank(\delta')\,.
        % \]
        %%
      \end{subsubcase}
      \begin{subsubcase}
        $e'\ne\nil$.
        %%
        Then~$\pi'$ contains one application of~\R{emit-int} which consumes
        one~$\ceu{\EmitInt(e')}$ expression from~$p_1$ and which implies
        $\pot'(p_1)>\pot'(p_1')$.  Thus
        \[
          \hskip1em\rank(\delta)\!=\!\<\pot'(p_1),n>
          >\<\pot'(p_1'),n+1>\!=\!\rank(\delta')\,.
        \]
        %%
        % \begin{align*}
        %   \rank(\delta)&=\<\pot'(p_1),n>\\
        %                &>\<\pot'(p_1'),n+1>=\rank(\delta')\,.
        % \end{align*}
        %%
      \end{subsubcase}
    \end{subcase}
    \begin{subsubcase}
      $\pot'(p)=\pot'(p_1)+\pot'(p_2)$.
      %%
      Then some execution path in~$p_1$ does not contain a
      (matching)~$\ceu{\Break}$ or~$\ceu{\AwaitExt}$ expression.
      Since~$p_1\ne\ceu{\Nop}$, a single~$\nst$ cannot restart the loop,
      which means that~$p_1'$ still contain some execution path in which
      a~$\ceu{\Break}$ or~$\ceu{\AwaitExt}$ does not occur.
      Hence~$\pot'(p')=\pot'(p_1')+\pot'(p_2)$.  The rest of this proof is
      similar to that of Case~\ref{lem.x.rank-nst-case1}.\qedhere
    \end{subsubcase}
  \end{case}
\end{proof}

The next theorem is a generalization of Lemma~\ref{lem.x.rank-nst}
for~$\nst[*]$ transitions.  Its proof is by induction on~$i$.

\begin{theorem}
  \label{thm.x.rank-nst-*}
  %%
  If~$\delta\nst[*]\delta'$ then~$\rank(\delta)\ge\rank(\delta')$.
\end{theorem}

We now state and prove the main result of this section,
Theorem~\ref{thm.x.term}, viz., the termination theorem for~$\trans[*]$.
The idea of the proof is that a sufficiently large sequence of~$\nst$
and~$\out$ transitions eventually decrease the rank of the current
description until an irreducible description is reached.  This irreducible
description is the final result of the reaction.
%%
\begin{theorem}[Termination]\label{thm.x.term}\strut\\
  %%
  For any~$\delta$, there is a~$\delta'_\#$ such
  that~$\delta\trans[*]\delta'_\#$.
\end{theorem}
\begin{proof}
  By lexicographic induction on~$\rank(\delta)$.  Let~$\delta=\<p,n,e>$ and
  $\rank(\delta)=\<i,j>$.
  \begin{basis}
    If~$\<i,j>=\<0,0>$ then~$\delta$ cannot be advanced by~$\out$, as~$j=0$
    implies~$e=\nil$ and~$n=0$ (neither~\R{push} nor~\R{pop} can be
    applied).  There are two possibilities:  either~$\delta$ is
    nested-irreducible or it is not.  In the first case, the theorem is
    trivially true, as~$\delta\nst[0]\delta_\Hnst$.  Suppose~$\delta$ is not
    nested-irreducible.  Then, by Theorem~\ref{thm.x.term-nst-*},
    $\delta\nst[*]\delta'_\Hnst$ for some~$\delta'_\Hnst$.  By
    Theorem~\ref{thm.x.rank-nst-*},
    $\<i,j>=\<0,0>\ge\rank(\delta')$,
    %%
    % \[
    %   \<i,j>=\<0,0>\ge\rank(\delta')\,,
    % \]
    %%
    which implies~$\rank(\delta')=\<0,0>$.
  \end{basis}
  \begin{induction}
    Let~$\<i,j>\ne\<0,0>$.
    %%
    There are two subcases depending on whether or not $\delta$~is
    nested-irreducible.
    \begin{case}
      \label{thm.x.term.Hnst}
      $\delta$~is nested-irreducible.
      %%
      If~$j=0$ then, by Definition~\ref{def.x.H}, $\delta_\#$, and
      thus~$\delta\trans[0]\delta_\#$.  Suppose that is not the case, i.e.,
      that $j>0$.  Then there are two subcases.
      \begin{subcase}
        \label{thm.x.term.Hnst-j>0-nonnil}
        $e\ne\nil$.
        %%
        Then, by~\R{out} and by Theorem~\ref{thm.x.term-nst-*}, there
        are~$\delta_1'$ and~$\delta'_\Hnst=\<p',n+1,e'>$ such that
        $\delta\outpush\delta_1'\nst[*]\delta'_\Hnst$.  Thus, by
        Lemma~\ref{lem.x.rank-out} and by Theorem~\ref{thm.x.rank-nst-*},
        \begin{align*}
          \rank(\delta)=\rank(\delta_1')=\<i,j>
                                        \ge\rank(\delta')=\<i',j'>\,.
        \end{align*}
        If~$e'=\nil$, then $i=i'$ and~$j=j'$, and the rest of this proof is
        similar to that of Case~\ref{thm.x.term.Hnst-j>0-nil} below.
        Otherwise, if~$e'\ne\nil$ then $i>i'$, since an~$\ceu{\EmitInt(e')}$
        was consumed by the nested transitions.  Thus,
        $\rank(\delta)>\rank(\delta')$.  By the induction hypothesis,
        $\delta'\trans[*]\delta''_\#$, for some~$\delta''_\#$.  Therefore,
        $\delta\trans[*]\delta''_\#$.
      \end{subcase}
      \begin{subcase}
        \label{thm.x.term.Hnst-j>0-nil}
        $e=\nil$.
        %%
        Then, since~$j>0$, $\delta\outpop\delta'$, for some~$\delta'$.  By
        item~\eqref{lem.rank-out-pop} of Lemma~\ref{lem.rank-out},
        $\rank(\delta)>\rank(\delta')$.  Hence, by the induction hypothesis,
        there is a~$\delta''_\#$ such that~$\delta'\trans[*]\delta''_\#$.
        Therefore, $\delta\trans[*]\delta''_\#$.
      \end{subcase}
    \end{case}
    \begin{case}
      $\delta$~is not nested-irreducible.
      %%
      Then~$e=\nil$ and, by Theorem~\ref{thm.x.term-nst-*}
      and~\ref{thm.x.rank-nst-*}, there is a~$\delta'_\Hnst$ such
      that~$\delta\nst[*]\delta'_\Hnst$
      with~$\rank(\delta)\ge\rank(\delta'_\Hnst)$.  The rest of this proof
      is similar to that of Case~\ref{thm.x.term.Hnst} above.\qedhere
    \end{case}
  \end{induction}
\end{proof}


\subsubsection{Memory bound}

As \CEU has no mechanism for heap allocation, unbounded iteration, or
general recursion, the maximum memory usage of a given \CEU program is
determined solely by the length of its code, the number of variables it
uses, and the size of the event stack that it requires to run.  The code
length and the number of variables used are easily determined by code
inspection.  The maximum size of the event stack during a reaction of
program~$p$ to external event~$e$ corresponds to~$\pot(p,e)$, i.e., to the
maximum number of internal events that~$p$ may emit in reaction to~$e$.
If~$p$ may react to external events~$e_1$, \dots,~$e_n$ then, in the worst
case, its event stack will need to
store~$\max\{\pot(p,e_1),\dots,\pot(p,e_n)\}$ events.

% - program is finite
% - lexical scope
%     - no heap allocation
% - no code reentrancy
%     - reexecution only due to loops
%     - loop reuse nested vars
