\section{\CEU}
\label{sec.ceu}

\CEU is a synchronous reactive language inspired by
Esterel~\cite{esterel.ieee91} in which programs advance in a sequence of
discrete reactions to external events.
%
\CEU is designed for control-intensive applications, supporting concurrent
lines of execution, known as \emph{trails}, and broadcast communication
through events.
%
Computations within a reaction (such as expressions, assignments, and
C~calls) execute in no time in accordance to the synchronous
hypothesis~\cite{rp.hypothesis}.
%
The \code{await} is the only \CEU statement that actually ``consumes'' time.
%%
An~\code{await} statement blocks the current trail allowing the program to
advance its other trails; when all trails are blocked, the reaction
terminates and control returns to the environment.

In \CEU, every execution path within a loop must contain at least one
\code{await} statement~\cite{ceu.sensys13,esterel.primer}.
%
This restriction, which is checked statically by the \CEU compiler, ensures
that every reaction runs in bounded time, eventually terminating with all
program trails blocked in \code{await} statements.
%
\CEU has a further restriction which it shares with Esterel and synchronous
languages in general~\cite{esterel.preemption}: computations that actually
take a non-negligible time to run (e.g., cryptography or image processing
algorithms) violate the zero-delay hypothesis, and thus cannot be directly
implemented.

Listing~\ref{lst.syntax} below shows a compact reference of~\CEU.

\bgroup
\def\T<#1>{\langle\mathit{#1}\rangle}
\def\C#1#2{\hfill\rmfamily\itshape\makebox[#1\columnwidth][l]{//~#2}}
\begin{lstlisting}[
  basicstyle=\ttfamily\footnotesize,
  caption={The concrete syntax of \CEU.},
  label={lst.syntax},
]
|\C{1.}{Declarations:}|
input  $\T<type>$ $\T<ids>$;|\C{.6}{declare external input events}|
output $\T<type>$ $\T<ids>$;|\C{.6}{declare external output events}|
event  $\T<type>$ $\T<ids>$;|\C{.6}{declare internal events}|
var    $\T<type>$ $\T<id>$ = $\T<exp>$;|\C{.6}{declare and initialize variable}|

|\C{1.}{Event handling:}|
$\T<id>$ = await $\T<id>$;|\C{.6}{await event and assign the received value}|
$\T<id>$ = await $\T<time>$;|\C{.6}{await time and assign the delayed delta}|
emit $\T<id>$($\T<exp>$);|\C{.6}{emit event passing a value}|

|\C{1.}{Control-flow:}|
$\T<stmt>$ ; $\T<stmt>$|\C{.45}{sequence}|
if $\T<exp>$ then $\T<stmts>$ else $\T<stmts>$ end|\C{.45}{conditional}|
loop do $\T<stmts>$ end|\C{.45}{repetition}|
finalize $\T<stmts>$ with $\T<stmts>$ end|\C{.45}{finalization}|

par/or  do $\T<stmts>$ with $\T<stmts>$ end|\C{.45}{aborts when any side terminates}|
par/and do $\T<stmts>$ with $\T<stmts>$ end|\C{.45}{terminates when all sides terminate}|
par     do $\T<stmts>$ with $\T<stmts>$ end|\C{.45}{never terminates}|

|\C{1.}{Assignment \& integration with C:}|
$\T<id>$ = $\T<exp>$;|\C{.45}{assign value to variable}|
_$\T<id>$($\T<exps>$)|\C{.45}{call C function (id starts with `\_'\,)}|
\end{lstlisting}
\egroup

To make matters concrete, consider the program of Listing~\ref{lst.ceu}.
%
This program continuously turns a LED~on for~2 seconds and off for~1 second,
and terminates after~1 minute of activity with the LED off.
%
The implementation uses a \code{par/or} to run two activities in parallel:
an endless loop that blinks the LED on and off (lines~2--7), and a single
statement that waits for~1 minute before terminating (line~9).
%
The \code{par/or} block stands for a \emph{parallel-or} composition; when
executed it creates~$n$ parallel trails (in this case, $n=2$) and rejoins
them when any of these~$n$ trails terminates, automatically aborting the
other trails.

\begin{lstlisting}[
  numbers=left,
  basicstyle=\ttfamily\footnotesize,
  float=h,
  caption={\CEU program that blinks a LED during 1 minute.},
  label={lst.ceu},
]
par/or do
    loop do
        _led(1);
        await 2s;
        _led(0);
        await 1s;
    end
with
    await 1min;
end
_led(0);
\end{lstlisting}

In \CEU, any identifier prefixed with an underscore (e.g., \code{_led}) is
passed unchanged to the underlying~C compiler.
%
Therefore, access to~C is straightforward and syntactically traceable.
%
To ensure that programs operate synchronously, the compiler environment
should only provide access to~C operations that are assumed run in zero
time, such as non-blocking~I/O and access to \code{struct}'s.


\subsection{External and Internal Events}
\label{sec.ceu.evts}

\CEU defines time as a discrete sequence of reactions to unique external
input events.
%
These external input events are received from the environment; each of them
delimits a new logical unit of time and triggers a corresponding reaction.
%
The life-cycle of a program in \CEU can be summarized as
follows~\cite{ceu.sensys13}.
%
\begin{enumerate}
\item The program initiates the ``boot reaction'' in a single trail
  (parallel constructs may create new trails).
  %
\item Active trails execute until they await or terminate, one after
  another.  This step is called a \emph{reaction chain}, and always runs in
  bounded time.
  %
\item When all its trails are blocked, the program goes idle and the
  environment takes control.
  %
\item On the occurrence of a new external input event, the environment
  awakes \emph{all} trails awaiting that event, and the program goes back to
  step~(ii).
\end{enumerate}

A program must react to an event completely before handling the next one.
%
By the synchronous hypothesis, the time the program spends in step~(ii)
above is conceptually zero (in practice, negligible).
%
Thus, from the point of view of the environment, the program is always
idle---on step~(iii).
%
In practice, if a new external input event occurs while a reaction is being
computed, the event is saved on a queue, which effectively schedules it to
be processed by a subsequent reaction.


\subsubsection*{External events and discrete time}

\begin{figure}[b]
\centering
\includegraphics[width=\columnwidth]{tick}
\caption{The discrete notion of time in \CEU.}
\label{fig.ticks}
\end{figure}

The processing of external input events induces a discrete notion of time in
\CEU.
%
Figure~\ref{fig.ticks} illustrates this notion.
%
The continuous timeline shows an absolute reference clock with ``physical
timestamps'' for the event occurrences (e.g., event~\code{C} occurs at
$17ms521us$).
%
The discrete timeline shows how the same occurring events fit in the logical
notion of time of \CEU.
%
The boot reaction \code{boot-0} happens before any input on program startup.
%
Event~\code{A} ``physically'' occurs during \code{boot-0} but, because time
is discrete, its corresponding reaction can only execute afterwards, at
logical instant~\code{A-1}.
%
Similarly, event~\code{B} occurs during~\code{A-1} and its reaction is
postponed to execute at~\code{B-2}.
%
Event~\code{C} also occurs during~\code{A-1} but its reaction must also wait
for~\code{B-2} to execute and so it is postponed to execute at~\code{C-3}.
%
Event~\code{D} occurs during an idle period and can start immediately at
\code{D-4}.
%
Finally, two instances of event~\code{E} occur during~\code{D-4}; they are
handled in the subsequent reactions~\code{E-5} and~\code{E-6}.

Unique input events imply mutually exclusive reactions, which execute
atomically and never overlap.
%
Automatic mutual exclusion is a prerequisite for deterministic reactions as
we discuss in Section~\ref{sec.sem}.
%
%8<- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
% \gl{A não ser que seja desenvolvido (e.g., explicado e comparado com
%   Esterel) eu acho que o parágrafo anterior é dispensável.}
% \fs{Tirei o "simplifies resoning about concurrency".
%     O resto do parágrafo é absoluto e tenta dar a intuição das condições para
%     ter determinismo.}
%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ->8

In practice, the synchronous hypothesis for \CEU holds if reaction rate is
faster than the rate of incoming input events.
%
Otherwise, the program continuously accumulates a delay between the real
occurrence time and actual reaction time of events.
%
In the soft real-time systems targeted by \CEU (e.g., sensor networks,
multimedia systems, interactive games, etc.) such delay and postponed
reactions might be tolerated by users as long as they are infrequent and the
application does not take too long to catch up with real time.


\subsubsection*{Internal events as subroutines}

In \CEU, the queue-based processing of events described previously applies
only to external input events, i.e., those events submitted to the program
by the environment.
%
Internal events, which are those events generated internally by the program
via \code{emit} statements, are processed in a stack-based manner.
%
These internal events provide a fine-grained execution control and, because
of their stack-based processing, can be used to implement a limited form of
subroutine, as illustrated in Listing~\ref{lst.sub} below.

\begin{lstlisting}[
  numbers=left,
  basicstyle=\ttfamily\footnotesize,
  float=h,
  caption={A \CEU program with a ``subroutine''.},
  label={lst.sub},
]
event int* inc;     // subroutine |`|inc|'|
par/or do
    loop do         // definitions are loops
        var int* p = await inc;
        *p = *p + 1;
    end
with
    var int v = 1;
    $\cdots$
    emit inc(&v);   // call |`|inc|'|
    _assert(v==2);  // after return
end
\end{lstlisting}
\vskip-\baselineskip

In Listing~\ref{lst.sub}, the ``subroutine'' \code{inc} is defined as a loop
(lines~3--6) that continuously awaits its identifying event (line~4), and
increments the value passed to it by reference (lines~5).
%
A trail in parallel (lines~8--11) invokes the subroutine through the
\code{emit} statement at line~10.
%
Given the stack-based execution mode of internal events, after the emit
statement at line~10 is executed, the calling trail pauses, the subroutine
awakes (line~4), runs its body (yielding \code{v=2}), loops, and awaits the
next ``call'' (line~4, again).
%
Only after this sequence does the calling trail resumes and moves on to
execute the assertion on line~11.

\CEU also supports nested \code{emit} invocations for internal events.
%
For instance, the body of the subroutine \code{inc} in Listing~\ref{lst.sub}
could \code{emit} another internal event after awaking (line~4), creating a
new level in the stack.
%
We can think of the stack as a record of the nested, fine-grained internal
reactions that happen inside the same bigger reaction to some external
event.

This form of subroutine has a significant limitation though: it cannot
express recursion (an \code{emit} to itself is always ignored as a running
trail cannot be waiting on itself).
%
That said, it is this very limitation that brings important safety
properties to subroutines.
%
First, such subroutines are guaranteed to react in bounded time.
%
Second, memory for locals is also bounded, not requiring data stacks.
%
Third, \CEU subroutines can be safely used by the other primitives of the
language, such as parallel compositions and the \code{await} statement,
without breaking the programming model.
%
In particular, after calling a subroutine these primitives wait while
keeping context information, such as locals and the program counter, which
makes the calls behave similarly to those of
coroutines~\cite{lua.coroutines}.
%
Finally, in previous work, we built other advanced control mechanisms on top
of internal events, such as resumable exceptions and reactive
variables~\cite{ceu.rem13}.
%
%In Section~\ref{sec.adv.excpt} we show how to use them to implement
%exceptions.
%
%8<- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
\gl{Revisei do início da Seção~2 até aqui.}
%- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ->8

\subsection{Shared-Memory Concurrency}
    - referenciar warnings

Embedded applications make extensive use of global memory and shared resources,
such as through memory-mapped registers and system calls to device drivers.
Hence, an important goal of \CEU is to ensure a reliable behavior for programs
with concurrent lines of execution sharing memory and interacting with the
environment.

\begin{figure}[h]
\begin{minipage}[h]{0.45\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3em]
input void A, B;
var int x = 1;
par/and do
    await A;
    x = x + 1;
with
    await B;
    x = x * 2;
end
\end{lstlisting}
\centering\small{\ax Accesses to \code{x} are never concurrent.}
\end{minipage}
%
\begin{minipage}[h]{0.45\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3em]
input void A;
var int y = 1;
par/and do
    await A;
    y = y + 1;
with
    await A;
    y = y * 2;
end
\end{lstlisting}
\centering\small{\bx Accesses to \code{y} are concurrent but deterministic.}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{ Shared-memory concurrency in \CEU:
example \ax is safe because the trails access \code{x} atomically in different
reactions;
example \bx is unsafe because both trails access \code{y} in the same reaction.
\label{lst.shared}
}
\end{figure}

In \CEU, when multiple trails are active during the same reaction, they are
scheduled in lexical order, i.e., in the order they appear in the program
source code.
%
For instance, consider the two examples in Figure~\ref{lst.shared}, both
defining a shared variable (ln. 2), and assigning to it in parallel trails (ln.
5, 8).

In the example \ax, the two assignments to \code{x} can only execute in
reactions to different events \code{A} and \code{B}, which cannot occur
simultaneously by definition (Section~\ref{sec.ceu.evts}).
Hence, for the sequence of events \code{A->B}, \code{x} becomes \code{4}
(\code{(1+1)*2}), while for \code{B->A}, \code{x} becomes \code{3}
(\code{(1*2)+1}).

In the example \bx, the two assignments to \code{y} are simultaneous because
they execute in reaction to the same event \code{A}.
Since \CEU employs lexical order for intra-reaction statements, the execution
is still deterministic, and \code{y} always becomes \code{4} (\code{(1+1)*2}).
%
However, that an (apparently innocuous) change in the order of trails modifies
the behavior of the program.
%
To mitigate this threat, \CEU performs concurrency checks at compile time to
detect conflicting accesses to shared variables:
if a variable is written in a trail segment, then a concurrent trail segment
cannot read or write to that variable~\cite{ceu.sensys13}.
%
Nonetheless, the static checks are optional and do not affect the semantics of
the language.

\subsection{Abortion and Finalization}

The \code{par/or} of \CEU is an \emph{orthogonal abortion
mechanism}~\cite{esterel.preemption} because the two sides in the composition
need not be tweaked with synchronization primitives or state variables in order
to affect each other.
%
In addition, abortion is \emph{immediate} in the sense that it executes
atomically in the current micro reaction.
%
Immediate orthogonal abortion is a distinctive feature of synchronous languages
and cannot be expressed effectively in traditional (asynchronous)
multi-threaded languages~\cite{esterel.preemption,sync_async.threadsstop}.

However, aborting lines of execution that deal with external resources may lead
to inconsistencies.
%
For this reason, \CEU provides a \code{finalize} construct to unconditionally
execute a series of statements even if the enclosing block is aborted.

\CEU also enforces the use of \code{finalize} for system calls that deal with
pointers representing resources, as illustrated in the two examples of
Figure~\ref{lst.fin.ceu}:
%
\begin{itemize}
\item If \CEU \textbf{passes} a pointer to a system call (ln. \ax:5), the
pointer represents a \textbf{local} resource (ln. \ax:2) that requires finalization
(ln. \ax:7).
\item If \CEU \textbf{receives} a pointer from a system call return (ln. \bx:4),
the pointer represents an \textbf{external} resource (ln. \bx:2) that requires
finalization (ln. \bx:6).
\end{itemize}
%
\CEU tracks the interaction of system calls with pointers and requires
finalization clauses to accompany them.
%
In the example in Figure~\ref{lst.fin.ceu}.a, the local variable \code{msg}
(ln. 2) is an internal resource passed as a pointer to \code{\_send\_request}
(ln. 5), which is an asynchronous call that transmits the buffer in the
background.
If the block aborts (ln. 11) before receiving an acknowledge from the
environment (ln. 9), the local \code{msg} goes out of scope and the external
transmission now holds a \emph{dangling pointer}.
The finalization ensures that the transmission also aborts (ln. 7).
%
In the example in Figure~\ref{lst.fin.ceu}.b, the call to \code{\_fopen} (ln.
4) returns an external file resource as a pointer.
If the block aborts (ln. 12) during the \code{await A} (ln. 9), the file
remains open as a \emph{memory leak}.
The finalization ensures that the file closes properly (ln. 6).
%
In both cases, the code does not compile without the \code{finalize}
construct.%
\footnote{
The compiler only forces the programmer to write the finalization clause, but
cannot check if it actually handles the resource properly.
}

The finalization mechanism of \CEU is fundamental to preserve the orthogonality
of the \code{par/or} construct since the clean up code is encapsulated in the
aborted trail itself.

\begin{figure}
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em,mathescape=true]
par/or do
   var _buffer_t msg;
   <...> // prepare msg
   finalize
      _send_request(&msg);
   with
      _send_cancel(&msg);
   end
   await SEND_ACK;
with
   <...>
end
.
\end{lstlisting}
\centering\small{\ax Local resource finalization}
\end{minipage}
%
\begin{minipage}[t]{0.48\linewidth}
\begin{lstlisting}[numbers=left,xleftmargin=3.5em]
par/or do
   var _FILE* f;
   finalize
      f = _fopen(...);
   with
      _fclose(f);
   end
   _fwrite(..., f);
   await A;
   _fwrite(..., f);
with
   <...>
end
\end{lstlisting}
\centering\small{\bx External resource finalization}
\end{minipage}
%\rule{8.4cm}{0.37pt}
\caption{
\CEU enforces the use of finalization to prevent \emph{dangling pointers} for
local resources and \emph{memory leaks} for external resources.
\label{lst.fin.ceu}
}
\end{figure}
